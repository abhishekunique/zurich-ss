{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/abhishekunique/zurich-ss/blob/main/Brax_PG_Fast_Zurich_SS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GJhPpM5ZPrpq"
   },
   "outputs": [],
   "source": [
    "#@title Import Brax and some helper modules\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import functools\n",
    "import math\n",
    "import time\n",
    "from typing import Any, Callable, Dict, Optional, Sequence, List\n",
    "\n",
    "try:\n",
    "  import brax\n",
    "except ImportError:\n",
    "  !pip install git+https://github.com/google/brax.git@main\n",
    "  clear_output()\n",
    "  import brax\n",
    "\n",
    "from brax import envs\n",
    "from brax.envs import to_torch\n",
    "from brax.io import metrics\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# have torch allocate on device first, to prevent JAX from swallowing up all the\n",
    "# GPU memory. By default JAX will pre-allocate 90% of the available GPU memory:\n",
    "# https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html\n",
    "v = torch.ones(1, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQFCkfu8Qwre"
   },
   "source": [
    "Here is a REINFORCE agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fWJE4b5BHeH7"
   },
   "outputs": [],
   "source": [
    "class REINFORCEAgent(nn.Module):\n",
    "\n",
    "  def __init__(self,\n",
    "               policy_layers: Sequence[int],\n",
    "               value_layers: Sequence[int],\n",
    "               discount: float, \n",
    "               entropy_weight: float,\n",
    "               device: str):\n",
    "    super(REINFORCEAgent, self).__init__()\n",
    "\n",
    "    policy = []\n",
    "    for w1, w2 in zip(policy_layers, policy_layers[1:]):\n",
    "      policy.append(nn.Linear(w1, w2))\n",
    "      policy.append(nn.SiLU())\n",
    "    policy.pop()  # drop the final activation\n",
    "    self.policy = nn.Sequential(*policy)\n",
    "\n",
    "    value = []\n",
    "    for w1, w2 in zip(value_layers, value_layers[1:]):\n",
    "      value.append(nn.Linear(w1, w2))\n",
    "      value.append(nn.SiLU())\n",
    "    value.pop()  # drop the final activation\n",
    "    self.value = nn.Sequential(*value)\n",
    "    self.discount = discount \n",
    "    self.entropy_weight = entropy_weight\n",
    "    self.device = device\n",
    "\n",
    "  @torch.jit.export\n",
    "  def dist_create(self, logits):\n",
    "    \"\"\"Normal followed by tanh.\n",
    "\n",
    "    torch.distribution doesn't work with torch.jit, so we roll our own.\"\"\"\n",
    "    loc, scale = torch.split(logits, logits.shape[-1] // 2, dim=-1)\n",
    "    scale = F.softplus(scale) + .001\n",
    "    return loc, scale\n",
    "\n",
    "  @torch.jit.export\n",
    "  def dist_sample_no_postprocess(self, loc, scale):\n",
    "    return torch.normal(loc, scale)\n",
    "\n",
    "  @torch.jit.export\n",
    "  def dist_entropy(self, loc, scale):\n",
    "    log_normalized = 0.5 * math.log(2 * math.pi) + torch.log(scale)\n",
    "    entropy = 0.5 + log_normalized\n",
    "    entropy = entropy * torch.ones_like(loc)\n",
    "    return entropy.sum(dim=-1)\n",
    "\n",
    "  @torch.jit.export\n",
    "  def dist_log_prob(self, loc, scale, dist):\n",
    "    log_unnormalized = -0.5 * ((dist - loc) / scale).square()\n",
    "    log_normalized = 0.5 * math.log(2 * math.pi) + torch.log(scale)\n",
    "    log_prob = log_unnormalized - log_normalized\n",
    "    return log_prob.sum(dim=-1)\n",
    "\n",
    "  @torch.jit.export\n",
    "  def get_logits_action(self, observation):\n",
    "    logits = self.policy(observation)\n",
    "    loc, scale = self.dist_create(logits)\n",
    "    action = self.dist_sample_no_postprocess(loc, scale)\n",
    "    entropy = self.dist_entropy(loc,  scale)\n",
    "    log_prob = self.dist_log_prob(loc,  scale, action)\n",
    "    return logits, action, entropy, log_prob\n",
    "\n",
    "  @torch.jit.export\n",
    "  def update_parameters(self, sample_trajs: List[torch.Tensor]):\n",
    "      states = sample_trajs[0]\n",
    "      actions = sample_trajs[1]\n",
    "      rewards = sample_trajs[2]\n",
    "      entropies = sample_trajs[3]\n",
    "      log_probs = sample_trajs[4]\n",
    "    \n",
    "      # Bookkeeping\n",
    "      R_EPS = 1e-9\n",
    "      R = torch.zeros(rewards.shape[0],rewards.shape[1]).cuda()\n",
    "      running_r = torch.zeros(rewards.shape[0],).cuda()\n",
    "      baseline_losses = torch.zeros(rewards.shape[1],).cuda()\n",
    "      \n",
    "      # Compute discounted cumulative sum TODO: Check this\n",
    "      for j in range(rewards.shape[1]):\n",
    "          i = rewards.shape[1] - 1 - j\n",
    "          running_r = self.discount * running_r + rewards[:, i]\n",
    "          baseline_rpred = self.value(states[:, i])[:, 0]\n",
    "          R[:, i] = running_r - baseline_rpred # Subtract the baseline\n",
    "          baseline_loss = torch.sum((baseline_rpred - running_r)**2)\n",
    "          baseline_losses[i] = baseline_loss\n",
    "          \n",
    "      # Normalize advantages\n",
    "      R_mean = torch.mean(R)\n",
    "      R_std = torch.std(R)\n",
    "      R = (R - R_mean) / (R_std + R_EPS)\n",
    "      \n",
    "      # Compute loss\n",
    "      loss = -(log_probs*R).sum() - self.entropy_weight*entropies.sum()\n",
    "      loss = loss / len(rewards)\n",
    "      baseline_loss = baseline_losses.sum() / len(rewards)\n",
    "      loss += baseline_loss\n",
    "      return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWbuk7IAR0SU"
   },
   "source": [
    "Finally, some code for unrolling and batching environment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D3y5o7-oSBm-"
   },
   "outputs": [],
   "source": [
    "def sample_trajectory(agent, env, num_steps):\n",
    "  \"\"\"Return step data over multple unrolls.\"\"\"\n",
    "  observation = env.reset()\n",
    "  states = []\n",
    "  actions = []\n",
    "  rewards = []\n",
    "  entropies = []\n",
    "  log_probs = []\n",
    "  for _ in range(num_steps):\n",
    "    logits, action, entropy, log_prob = agent.get_logits_action(observation)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    states.append(observation[None])\n",
    "    actions.append(action[None])\n",
    "    rewards.append(reward[None])\n",
    "    entropies.append(entropy[None])\n",
    "    log_probs.append(log_prob[None])\n",
    "  return [torch.transpose(torch.cat(states), 0, 1), \n",
    "          torch.transpose(torch.cat(actions), 0, 1),\n",
    "          torch.transpose(torch.cat(rewards), 0, 1), \n",
    "          torch.transpose(torch.cat(entropies), 0, 1),\n",
    "          torch.transpose(torch.cat(log_probs), 0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_name, num_envs, episode_length, device):\n",
    "  gym_name = f'brax-{env_name}-v0'\n",
    "  if gym_name not in gym.envs.registry.env_specs:\n",
    "    entry_point = functools.partial(envs.create_gym_env, env_name=env_name)\n",
    "    gym.register(gym_name, entry_point=entry_point)\n",
    "  env = gym.make(gym_name, batch_size=num_envs, episode_length=episode_length)\n",
    "  env = to_torch.JaxToTorchWrapper(env, device=device)\n",
    "  return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    env_name: str = 'reacher',\n",
    "    num_envs: int = 2048,\n",
    "    episode_length: int = 100,\n",
    "    device: str = 'cuda',\n",
    "    num_epochs: int = 200,\n",
    "    discount: float = 0.99,\n",
    "    entropy_weight: float = 0.0001, \n",
    "    hidden_size: int = 128,\n",
    "    learning_rate: float = 3e-4,\n",
    "):\n",
    "\n",
    "  # Define environment  \n",
    "  env = make_env(env_name, num_envs, episode_length, device)\n",
    "    \n",
    "  # env warmup\n",
    "  env.reset()\n",
    "  action = torch.zeros(env.action_space.shape).to(device)\n",
    "  env.step(action)\n",
    "\n",
    "  # create the agent\n",
    "  policy_layers = [env.observation_space.shape[-1], hidden_size, hidden_size, env.action_space.shape[-1] * 2]\n",
    "  value_layers = [env.observation_space.shape[-1], hidden_size, hidden_size, 1]\n",
    "  agent = REINFORCEAgent(policy_layers, value_layers, discount, entropy_weight, device)\n",
    "  agent = torch.jit.script(agent.to(device))\n",
    "  optimizer = optim.Adam(agent.parameters())\n",
    "    \n",
    "  # Bookkeeping\n",
    "  returns = []\n",
    "\n",
    "  # Training loop\n",
    "  for iter_num in range(num_epochs):\n",
    "    # Sample trajectories\n",
    "    sample_trajs = sample_trajectory(agent, env, episode_length)\n",
    "\n",
    "    loss = agent.update_parameters(sample_trajs)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    rewards_np = sample_trajs[2].cpu().numpy().sum(axis=-1).mean()\n",
    "    print(\"Episode: {}, reward: {}\".format(iter_num, rewards_np))\n",
    "    returns.append(rewards_np)\n",
    "\n",
    "  plt.plot(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "B-lrKHvkUeYM",
    "outputId": "3acec01a-935e-4ac3-fd4d-c246a4e4e85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, reward: -117.34770202636719\n",
      "Episode: 1, reward: -113.21853637695312\n",
      "Episode: 2, reward: -109.62570190429688\n",
      "Episode: 3, reward: -105.3235092163086\n",
      "Episode: 4, reward: -101.61454772949219\n",
      "Episode: 5, reward: -98.49986267089844\n",
      "Episode: 6, reward: -94.55696105957031\n",
      "Episode: 7, reward: -90.96101379394531\n",
      "Episode: 8, reward: -87.97770690917969\n",
      "Episode: 9, reward: -84.19537353515625\n",
      "Episode: 10, reward: -80.78797912597656\n",
      "Episode: 11, reward: -77.3096694946289\n",
      "Episode: 12, reward: -73.7021484375\n",
      "Episode: 13, reward: -70.43171691894531\n",
      "Episode: 14, reward: -66.47065734863281\n",
      "Episode: 15, reward: -63.09730529785156\n",
      "Episode: 16, reward: -59.35502624511719\n",
      "Episode: 17, reward: -55.87764358520508\n",
      "Episode: 18, reward: -52.15184783935547\n",
      "Episode: 19, reward: -48.36937713623047\n",
      "Episode: 20, reward: -44.92522048950195\n",
      "Episode: 21, reward: -41.5605583190918\n",
      "Episode: 22, reward: -38.430328369140625\n",
      "Episode: 23, reward: -35.344635009765625\n",
      "Episode: 24, reward: -32.98308563232422\n",
      "Episode: 25, reward: -31.15897560119629\n",
      "Episode: 26, reward: -29.108535766601562\n",
      "Episode: 27, reward: -27.466386795043945\n",
      "Episode: 28, reward: -26.056251525878906\n",
      "Episode: 29, reward: -24.749862670898438\n",
      "Episode: 30, reward: -23.55612564086914\n",
      "Episode: 31, reward: -22.574079513549805\n",
      "Episode: 32, reward: -21.769668579101562\n",
      "Episode: 33, reward: -21.76498031616211\n",
      "Episode: 34, reward: -20.962982177734375\n",
      "Episode: 35, reward: -20.731700897216797\n",
      "Episode: 36, reward: -20.718090057373047\n",
      "Episode: 37, reward: -19.417333602905273\n",
      "Episode: 38, reward: -18.12398910522461\n",
      "Episode: 39, reward: -22.284133911132812\n",
      "Episode: 40, reward: -17.65044403076172\n",
      "Episode: 41, reward: -18.829544067382812\n",
      "Episode: 42, reward: -20.540767669677734\n",
      "Episode: 43, reward: -20.378576278686523\n",
      "Episode: 44, reward: -19.376022338867188\n",
      "Episode: 45, reward: -17.977903366088867\n",
      "Episode: 46, reward: -21.393001556396484\n",
      "Episode: 47, reward: -17.0650634765625\n",
      "Episode: 48, reward: -18.68608283996582\n",
      "Episode: 49, reward: -17.982587814331055\n",
      "Episode: 50, reward: -17.518932342529297\n",
      "Episode: 51, reward: -17.354310989379883\n",
      "Episode: 52, reward: -17.61019515991211\n",
      "Episode: 53, reward: -18.144927978515625\n",
      "Episode: 54, reward: -18.32143783569336\n",
      "Episode: 55, reward: -17.708755493164062\n",
      "Episode: 56, reward: -17.29653549194336\n",
      "Episode: 57, reward: -18.470029830932617\n",
      "Episode: 58, reward: -19.620176315307617\n",
      "Episode: 59, reward: -19.952539443969727\n",
      "Episode: 60, reward: -19.254859924316406\n",
      "Episode: 61, reward: -20.385597229003906\n",
      "Episode: 62, reward: -20.055553436279297\n",
      "Episode: 63, reward: -16.760108947753906\n",
      "Episode: 64, reward: -16.53603744506836\n",
      "Episode: 65, reward: -17.75161361694336\n",
      "Episode: 66, reward: -20.028709411621094\n",
      "Episode: 67, reward: -22.059513092041016\n",
      "Episode: 68, reward: -23.572734832763672\n",
      "Episode: 69, reward: -22.141216278076172\n",
      "Episode: 70, reward: -20.97833251953125\n",
      "Episode: 71, reward: -19.58289337158203\n",
      "Episode: 72, reward: -18.040496826171875\n",
      "Episode: 73, reward: -16.671215057373047\n",
      "Episode: 74, reward: -15.784669876098633\n",
      "Episode: 75, reward: -16.376941680908203\n",
      "Episode: 76, reward: -17.066974639892578\n",
      "Episode: 77, reward: -16.904468536376953\n",
      "Episode: 78, reward: -15.968368530273438\n",
      "Episode: 79, reward: -17.278093338012695\n",
      "Episode: 80, reward: -18.145225524902344\n",
      "Episode: 81, reward: -18.084312438964844\n",
      "Episode: 82, reward: -18.365840911865234\n",
      "Episode: 83, reward: -20.691402435302734\n",
      "Episode: 84, reward: -22.401264190673828\n",
      "Episode: 85, reward: -22.2377986907959\n",
      "Episode: 86, reward: -19.45804214477539\n",
      "Episode: 87, reward: -18.365903854370117\n",
      "Episode: 88, reward: -17.704891204833984\n",
      "Episode: 89, reward: -17.56427764892578\n",
      "Episode: 90, reward: -17.721508026123047\n",
      "Episode: 91, reward: -17.63271713256836\n",
      "Episode: 92, reward: -19.195045471191406\n",
      "Episode: 93, reward: -22.376419067382812\n",
      "Episode: 94, reward: -22.48385238647461\n",
      "Episode: 95, reward: -21.605010986328125\n",
      "Episode: 96, reward: -18.559715270996094\n",
      "Episode: 97, reward: -16.145954132080078\n",
      "Episode: 98, reward: -16.110809326171875\n",
      "Episode: 99, reward: -16.108917236328125\n",
      "Episode: 100, reward: -15.869093894958496\n",
      "Episode: 101, reward: -16.10811424255371\n",
      "Episode: 102, reward: -16.592864990234375\n",
      "Episode: 103, reward: -16.970836639404297\n",
      "Episode: 104, reward: -17.657955169677734\n",
      "Episode: 105, reward: -17.257122039794922\n",
      "Episode: 106, reward: -17.406513214111328\n",
      "Episode: 107, reward: -20.599628448486328\n",
      "Episode: 108, reward: -24.417644500732422\n",
      "Episode: 109, reward: -23.81890869140625\n",
      "Episode: 110, reward: -24.158920288085938\n",
      "Episode: 111, reward: -23.905555725097656\n",
      "Episode: 112, reward: -23.850753784179688\n",
      "Episode: 113, reward: -23.468374252319336\n",
      "Episode: 114, reward: -23.77806854248047\n",
      "Episode: 115, reward: -24.7244873046875\n",
      "Episode: 116, reward: -25.639333724975586\n",
      "Episode: 117, reward: -26.283702850341797\n",
      "Episode: 118, reward: -26.56562042236328\n",
      "Episode: 119, reward: -25.55668830871582\n",
      "Episode: 120, reward: -25.476741790771484\n",
      "Episode: 121, reward: -25.503097534179688\n",
      "Episode: 122, reward: -25.170963287353516\n",
      "Episode: 123, reward: -25.44981575012207\n",
      "Episode: 124, reward: -25.64246368408203\n",
      "Episode: 125, reward: -25.431732177734375\n",
      "Episode: 126, reward: -24.840076446533203\n",
      "Episode: 127, reward: -24.733522415161133\n",
      "Episode: 128, reward: -24.928377151489258\n",
      "Episode: 129, reward: -24.279739379882812\n",
      "Episode: 130, reward: -23.198223114013672\n",
      "Episode: 131, reward: -22.500089645385742\n",
      "Episode: 132, reward: -21.87697982788086\n",
      "Episode: 133, reward: -21.50098991394043\n",
      "Episode: 134, reward: -20.853342056274414\n",
      "Episode: 135, reward: -20.605987548828125\n",
      "Episode: 136, reward: -20.22727394104004\n",
      "Episode: 137, reward: -20.070751190185547\n",
      "Episode: 138, reward: -19.89551544189453\n",
      "Episode: 139, reward: -19.092445373535156\n",
      "Episode: 140, reward: -17.85467529296875\n",
      "Episode: 141, reward: -18.68106460571289\n",
      "Episode: 142, reward: -20.259002685546875\n",
      "Episode: 143, reward: -19.869853973388672\n",
      "Episode: 144, reward: -17.6029052734375\n",
      "Episode: 145, reward: -19.592487335205078\n",
      "Episode: 146, reward: -20.254283905029297\n",
      "Episode: 147, reward: -21.858402252197266\n",
      "Episode: 148, reward: -22.371828079223633\n",
      "Episode: 149, reward: -22.964780807495117\n",
      "Episode: 150, reward: -23.459169387817383\n",
      "Episode: 151, reward: -23.520214080810547\n",
      "Episode: 152, reward: -23.959575653076172\n",
      "Episode: 153, reward: -23.31441307067871\n",
      "Episode: 154, reward: -23.13117790222168\n",
      "Episode: 155, reward: -22.957752227783203\n",
      "Episode: 156, reward: -22.175167083740234\n",
      "Episode: 157, reward: -21.90386199951172\n",
      "Episode: 158, reward: -21.643341064453125\n",
      "Episode: 159, reward: -21.50596046447754\n",
      "Episode: 160, reward: -21.23711395263672\n",
      "Episode: 161, reward: -20.391481399536133\n",
      "Episode: 162, reward: -19.6417293548584\n",
      "Episode: 163, reward: -19.292112350463867\n",
      "Episode: 164, reward: -16.601184844970703\n",
      "Episode: 165, reward: -18.310836791992188\n",
      "Episode: 166, reward: -17.58089828491211\n",
      "Episode: 167, reward: -17.21753692626953\n",
      "Episode: 168, reward: -17.568641662597656\n",
      "Episode: 169, reward: -16.743215560913086\n",
      "Episode: 170, reward: -17.980541229248047\n",
      "Episode: 171, reward: -16.85232925415039\n",
      "Episode: 172, reward: -17.559864044189453\n",
      "Episode: 173, reward: -18.66158676147461\n",
      "Episode: 174, reward: -18.618568420410156\n",
      "Episode: 175, reward: -19.190885543823242\n",
      "Episode: 176, reward: -19.288869857788086\n",
      "Episode: 177, reward: -19.10138511657715\n",
      "Episode: 178, reward: -20.238143920898438\n",
      "Episode: 179, reward: -20.50029754638672\n",
      "Episode: 180, reward: -20.64965057373047\n",
      "Episode: 181, reward: -19.62987518310547\n",
      "Episode: 182, reward: -20.19882583618164\n",
      "Episode: 183, reward: -21.280540466308594\n",
      "Episode: 184, reward: -22.12473487854004\n",
      "Episode: 185, reward: -22.1928653717041\n",
      "Episode: 186, reward: -22.13959503173828\n",
      "Episode: 187, reward: -22.64581871032715\n",
      "Episode: 188, reward: -23.823528289794922\n",
      "Episode: 189, reward: -24.147871017456055\n",
      "Episode: 190, reward: -25.117692947387695\n",
      "Episode: 191, reward: -26.22920036315918\n",
      "Episode: 192, reward: -26.896038055419922\n",
      "Episode: 193, reward: -28.59121322631836\n",
      "Episode: 194, reward: -29.946542739868164\n",
      "Episode: 195, reward: -30.543502807617188\n",
      "Episode: 196, reward: -31.99353790283203\n",
      "Episode: 197, reward: -34.03608703613281\n",
      "Episode: 198, reward: -38.01834487915039\n",
      "Episode: 199, reward: -40.81256866455078\n",
      "GPU 0: Tesla T4 (UUID: GPU-c2723529-07db-5da4-4702-d951a1ac494e)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Brax PG Fast Zurich SS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_sOmCoOrF0F8"
      },
      "outputs": [],
      "source": [
        "#@title Import Brax and some helper modules\n",
        "\n",
        "import functools\n",
        "import time\n",
        "\n",
        "from IPython.display import HTML, Image \n",
        "import gym\n",
        "\n",
        "try:\n",
        "  import brax\n",
        "except ImportError:\n",
        "  from IPython.display import clear_output \n",
        "  !pip install git+https://github.com/google/brax.git@main\n",
        "  clear_output()\n",
        "  import brax\n",
        "\n",
        "from brax import envs\n",
        "from brax import jumpy as jp\n",
        "from brax.envs import to_torch\n",
        "from brax.io import html\n",
        "from brax.io import image\n",
        "import jax\n",
        "from jax import numpy as jnp\n",
        "import torch\n",
        "v = torch.ones(1, device='cuda')  # init torch cuda before jax\n",
        "\n",
        "import sys\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils as utils\n",
        "import torchvision.transforms as T\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import argparse, math, os\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym import wrappers\n",
        "import brax\n",
        "from brax import envs\n",
        "from brax.envs import to_torch\n",
        "import functools\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.utils as utils\n",
        "\n",
        "\n",
        "pi = Variable(torch.FloatTensor([math.pi])).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "\n",
        "class NormalizedActions(gym.ActionWrapper):\n",
        "\n",
        "    def action(self, action):\n",
        "        action = (action + 1) / 2  # [-1, 1] => [0, 1]\n",
        "        action *= (self.action_space.high - self.action_space.low)\n",
        "        action += self.action_space.low\n",
        "        return action\n",
        "\n",
        "    def reverse_action(self, action):\n",
        "        action -= self.action_space.low\n",
        "        action /= (self.action_space.high - self.action_space.low)\n",
        "        action = action * 2 - 1\n",
        "        return actions\n"
      ],
      "metadata": {
        "id": "EvMfw-aS8OzG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normal(x, mu, sigma_sq):\n",
        "    a = (-1*(Variable(x)-mu).pow(2)/(2*sigma_sq)).exp()\n",
        "    b = 1/(2*sigma_sq*pi.expand_as(sigma_sq)).sqrt()\n",
        "    return a*b\n",
        "\n",
        "\n",
        "class Policy(nn.Module):\n",
        "    def __init__(self, hidden_size, num_inputs, action_space):\n",
        "        super(Policy, self).__init__()\n",
        "        self.action_space = action_space\n",
        "        num_outputs = action_space.shape[0]\n",
        "\n",
        "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, num_outputs)\n",
        "        self.linear2_ = nn.Linear(hidden_size, num_outputs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        x = F.relu(self.linear1(x))\n",
        "        mu = self.linear2(x)\n",
        "        sigma_sq = self.linear2_(x)\n",
        "\n",
        "        return mu, sigma_sq\n",
        "\n",
        "\n",
        "class REINFORCE:\n",
        "    def __init__(self, hidden_size, num_inputs, action_space):\n",
        "        self.action_space = action_space\n",
        "        self.model = Policy(hidden_size, num_inputs, action_space)\n",
        "        self.model = self.model.cuda()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "        self.model.train()\n",
        "\n",
        "    def select_action(self, state):\n",
        "        mu, sigma_sq = self.model(Variable(state).cuda())\n",
        "        sigma_sq = F.softplus(sigma_sq)\n",
        "\n",
        "        eps = torch.randn(mu.size())\n",
        "        # calculate the probability\n",
        "        action = (mu + sigma_sq.sqrt()*Variable(eps).cuda()).data\n",
        "        prob = normal(action, mu, sigma_sq)\n",
        "        entropy = -0.5*((sigma_sq+2*pi.expand_as(sigma_sq)).log()+1)\n",
        "\n",
        "        log_prob = prob.log()\n",
        "        return action, log_prob, entropy\n",
        "\n",
        "    def update_parameters(self, rewards, log_probs, entropies, gamma):\n",
        "        R = torch.zeros(1, 1)\n",
        "        loss = 0\n",
        "        for i in reversed(range(len(rewards))):\n",
        "            R = gamma * R + rewards[i]\n",
        "            loss = loss - (log_probs[i]*(Variable(R).expand_as(log_probs[i])).cuda()).sum() - (0.0001*entropies[i].cuda()).sum()\n",
        "        loss = loss / len(rewards)\n",
        "\t\t\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        utils.clip_grad_norm(self.model.parameters(), 40)\n",
        "        self.optimizer.step()\n"
      ],
      "metadata": {
        "id": "F8MxQcFu8R0A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seed = 0\n",
        "gamma = 0.99\n",
        "exploration_end = 100\n",
        "num_steps = 1000\n",
        "num_episodes = 2000\n",
        "hidden_size = 128\n",
        "\n",
        "\n",
        "entry_point = functools.partial(envs.create_gym_env, env_name='reacher')\n",
        "if 'brax-reacher-v0' not in gym.envs.registry.env_specs:\n",
        "    gym.register('brax-reacher-v0', entry_point=entry_point)\n",
        "env = gym.make('brax-reacher-v0')\n",
        "env = to_torch.JaxToTorchWrapper(env, device='cpu')\n",
        "\n",
        "# if type(env.action_space) != gym.spaces.discrete.Discrete:\n",
        "#     from reinforce_continuous import REINFORCE\n",
        "#     # env = NormalizedActions(gym.make(env_name))\n",
        "# else:\n",
        "#     from reinforce_discrete import REINFORCE\n",
        "\n",
        "env.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "agent = REINFORCE(hidden_size, env.observation_space.shape[0], env.action_space)\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    state = env.reset()[None]\n",
        "    entropies = []\n",
        "    log_probs = []\n",
        "    rewards = []\n",
        "    for t in range(num_steps):\n",
        "        action, log_prob, entropy = agent.select_action(state)\n",
        "        action = action.cpu()\n",
        "        \n",
        "        next_state, reward, done, _ = env.step(action.numpy()[0])\n",
        "        done = done.cpu().numpy().item()\n",
        "        entropies.append(entropy)\n",
        "        log_probs.append(log_prob)\n",
        "        rewards.append(reward.cpu().numpy().item())\n",
        "        state = next_state[None]\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    agent.update_parameters(rewards, log_probs, entropies, gamma)\n",
        "\n",
        "    print(\"Episode: {}, reward: {}\".format(i_episode, np.sum(rewards)))\n",
        "\t\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "8r_Tyu_A8MFq",
        "outputId": "e9eec60a-d232-473e-af75-ad8de38cf216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-62536963a85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Episode: {}, reward: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_episode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Brax Environments.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}